{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the Baselines and Bigrams: Simple, Good Sentiment and Topic Classification paper\n",
    "Specifically trying MNB and NBSVM\n",
    "https://www.aclweb.org/anthology/P12-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, log_loss\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "import spacy\n",
    "import time\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['comment_text']],\n",
    "                                                    df.drop(columns=['id', 'comment_text']),\n",
    "                                                    test_size=0.2)\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab[u'you'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    tokens = nlp(unicode(s))\n",
    "    return [t.lemma_ if t.lemma_ != u'-PRON-' else t.text for t in tokens if not t.is_stop and not t.is_space and not t.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(strip_accents='unicode', tokenizer=tokenize, ngram_range=(1,2),\n",
    "                            max_df=0.9, min_df=3, sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.fit_transform(X_train.comment_text)\n",
    "X_test_tfidf = tfidf_vec.transform(X_test.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r(X, y_pos, y_neg, alpha=1.):\n",
    "    p = X[y_pos].sum(0) + alpha\n",
    "    q = X[y_neg].sum(0) + alpha\n",
    "    \n",
    "    p /= sum(p) + alpha\n",
    "    q /= sum(q) + alpha\n",
    "    \n",
    "    return np.log(p, q).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    'tol': [1e-3, 1e-4],\n",
    "    'C': [1., 4., 8., 16.]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training toxic\n",
      "Took 128.82940197 seconds\n",
      "Training severe_toxic\n",
      "Took 139.745584965 seconds\n",
      "Training obscene\n",
      "Took 118.517186165 seconds\n",
      "Training threat\n",
      "Took 119.408869028 seconds\n",
      "Training insult\n",
      "Took 134.984273911 seconds\n",
      "Training identity_hate\n",
      "Took 138.027602911 seconds\n"
     ]
    }
   ],
   "source": [
    "best_params = {}\n",
    "best_estimators = {}\n",
    "rs = {}\n",
    "best_score = {}\n",
    "test_score = {}\n",
    "for c in classes:\n",
    "    print 'Training {}'.format(c)\n",
    "    t = time.time()\n",
    "    y_pos = y_train[y_train[c] == 1][c].values\n",
    "    y_neg = y_train[y_train[c] == 0][c].values\n",
    "    r = get_r(X_train_tfidf, y_pos, y_neg)\n",
    "    clf = GridSearchCV(lr, search_params, scoring='neg_log_loss', cv=10)\n",
    "    clf.fit(X_train_tfidf.multiply(r), y_train[c].values)\n",
    "    best_params[c] = clf.best_params_\n",
    "    best_estimators[c] = clf.best_estimator_\n",
    "    rs[c] = r\n",
    "    best_score[c] = clf.best_score_\n",
    "    test_score[c] = log_loss(y_test[c].values, clf.best_estimator_.predict_proba(X_test_tfidf.multiply(r))[:,1])\n",
    "    print 'Took {} seconds'.format(time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Validation score: -0.0543013555103\n",
      "Mean Test score: 0.0511423051548\n"
     ]
    }
   ],
   "source": [
    "print 'Mean Validation score: {}'.format(np.mean(best_score.values()))\n",
    "print 'Mean Test score: {}'.format(np.mean(test_score.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters by Class:\n",
      "toxic {'C': 16.0, 'tol': 0.0001}\n",
      "Confusion matrix\n",
      "[[17214   173]\n",
      " [  576  1208]]\n",
      "severe_toxic {'C': 8.0, 'tol': 0.0001}\n",
      "Confusion matrix\n",
      "[[18929    39]\n",
      " [  153    50]]\n",
      "obscene {'C': 16.0, 'tol': 0.0001}\n",
      "Confusion matrix\n",
      "[[18060    85]\n",
      " [  330   696]]\n",
      "threat {'C': 16.0, 'tol': 0.0001}\n",
      "Confusion matrix\n",
      "[[19111     7]\n",
      " [   40    13]]\n",
      "insult {'C': 8.0, 'tol': 0.001}\n",
      "Confusion matrix\n",
      "[[18108   126]\n",
      " [  419   518]]\n",
      "identity_hate {'C': 16.0, 'tol': 0.001}\n",
      "Confusion matrix\n",
      "[[19001    17]\n",
      " [  116    37]]\n"
     ]
    }
   ],
   "source": [
    "print 'Best parameters by Class:'\n",
    "for c in classes:\n",
    "    print c, best_params[c]\n",
    "    print 'Confusion matrix'\n",
    "    print confusion_matrix(y_test[c], [1 if x > 0.5 else 0 for x in best_estimators[c].predict_proba(X_test_tfidf.multiply(rs[c]))[:,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False Negative rate is really high likely due to severe class imbalance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('train.csv')\n",
    "df_nblr = pd.read_csv('train_nblr.csv', usecols=classes).rename(columns={c:'nblr_'+c for c in classes})\n",
    "df_cnn = pd.read_csv('train_CNN_keras_epoch1.csv', usecols=classes).rename(columns={c:'cnn_'+c for c in classes})\n",
    "df_rnn = pd.read_csv('train_RNN_GRU.csv', usecols=classes).rename(columns={c:'rnn_'+c for c in classes})\n",
    "df = pd.concat([df_raw, df_nblr, df_cnn, df_rnn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['id', 'comment_text']+classes)\n",
    "y = df[classes]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'min_child_weight': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "[0]\ttrain-logloss:0.444346\ttest-logloss:0.445388\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.032916\ttest-logloss:0.037931\n",
      "[20]\ttrain-logloss:0.015112\ttest-logloss:0.022423\n",
      "[30]\ttrain-logloss:0.012471\ttest-logloss:0.021377\n",
      "[40]\ttrain-logloss:0.010845\ttest-logloss:0.021317\n",
      "[50]\ttrain-logloss:0.009736\ttest-logloss:0.021396\n",
      "[60]\ttrain-logloss:0.008664\ttest-logloss:0.021792\n",
      "[70]\ttrain-logloss:0.007692\ttest-logloss:0.021959\n",
      "[80]\ttrain-logloss:0.006728\ttest-logloss:0.02242\n",
      "Stopping. Best iteration:\n",
      "[37]\ttrain-logloss:0.011286\ttest-logloss:0.02126\n",
      "\n",
      "severe_toxic\n",
      "[0]\ttrain-logloss:0.439813\ttest-logloss:0.440253\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.021488\ttest-logloss:0.02409\n",
      "[20]\ttrain-logloss:0.004753\ttest-logloss:0.00849\n",
      "[30]\ttrain-logloss:0.003227\ttest-logloss:0.007691\n",
      "[40]\ttrain-logloss:0.002638\ttest-logloss:0.007742\n",
      "[50]\ttrain-logloss:0.002215\ttest-logloss:0.00797\n",
      "[60]\ttrain-logloss:0.001904\ttest-logloss:0.008181\n",
      "[70]\ttrain-logloss:0.001679\ttest-logloss:0.00812\n",
      "Stopping. Best iteration:\n",
      "[26]\ttrain-logloss:0.003584\ttest-logloss:0.007666\n",
      "\n",
      "obscene\n",
      "[0]\ttrain-logloss:0.441678\ttest-logloss:0.442004\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.025843\ttest-logloss:0.029211\n",
      "[20]\ttrain-logloss:0.008402\ttest-logloss:0.013798\n",
      "[30]\ttrain-logloss:0.006161\ttest-logloss:0.01283\n",
      "[40]\ttrain-logloss:0.005004\ttest-logloss:0.012664\n",
      "[50]\ttrain-logloss:0.004172\ttest-logloss:0.013235\n",
      "[60]\ttrain-logloss:0.003625\ttest-logloss:0.013333\n",
      "[70]\ttrain-logloss:0.003174\ttest-logloss:0.013402\n",
      "[80]\ttrain-logloss:0.002759\ttest-logloss:0.013533\n",
      "Stopping. Best iteration:\n",
      "[37]\ttrain-logloss:0.0053\ttest-logloss:0.012657\n",
      "\n",
      "threat\n",
      "[0]\ttrain-logloss:0.43839\ttest-logloss:0.43854\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.018363\ttest-logloss:0.018976\n",
      "[20]\ttrain-logloss:0.002152\ttest-logloss:0.003268\n",
      "[30]\ttrain-logloss:0.00114\ttest-logloss:0.002453\n",
      "[40]\ttrain-logloss:0.000984\ttest-logloss:0.002488\n",
      "[50]\ttrain-logloss:0.000895\ttest-logloss:0.002479\n",
      "[60]\ttrain-logloss:0.00082\ttest-logloss:0.002482\n",
      "[70]\ttrain-logloss:0.000776\ttest-logloss:0.002566\n",
      "[80]\ttrain-logloss:0.000727\ttest-logloss:0.002597\n",
      "Stopping. Best iteration:\n",
      "[32]\ttrain-logloss:0.001102\ttest-logloss:0.002401\n",
      "\n",
      "insult\n",
      "[0]\ttrain-logloss:0.44379\ttest-logloss:0.444177\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.030811\ttest-logloss:0.034574\n",
      "[20]\ttrain-logloss:0.013119\ttest-logloss:0.018918\n",
      "[30]\ttrain-logloss:0.010581\ttest-logloss:0.017454\n",
      "[40]\ttrain-logloss:0.008794\ttest-logloss:0.017586\n",
      "[50]\ttrain-logloss:0.007501\ttest-logloss:0.017868\n",
      "[60]\ttrain-logloss:0.006375\ttest-logloss:0.018331\n",
      "[70]\ttrain-logloss:0.005657\ttest-logloss:0.018589\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-logloss:0.010805\ttest-logloss:0.01745\n",
      "\n",
      "identity_hate\n",
      "[0]\ttrain-logloss:0.440838\ttest-logloss:0.44105\n",
      "Multiple eval metrics have been passed: 'test-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.020841\ttest-logloss:0.023027\n",
      "[20]\ttrain-logloss:0.003974\ttest-logloss:0.007152\n",
      "[30]\ttrain-logloss:0.002518\ttest-logloss:0.00609\n",
      "[40]\ttrain-logloss:0.002048\ttest-logloss:0.006211\n",
      "[50]\ttrain-logloss:0.001764\ttest-logloss:0.006236\n",
      "[60]\ttrain-logloss:0.001548\ttest-logloss:0.006333\n",
      "[70]\ttrain-logloss:0.001392\ttest-logloss:0.00649\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-logloss:0.002584\ttest-logloss:0.006076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_test = []\n",
    "trees = {}\n",
    "for c in classes:\n",
    "    print c\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train[[c]])\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test[[c]])\n",
    "    \n",
    "    bst = xgb.train(xgb_params, dtrain, 500, [(dtrain, 'train'), (dtest, 'test')],\n",
    "                    early_stopping_rounds=50, verbose_eval=10)\n",
    "    trees[c] = bst\n",
    "    xgb_test.append(log_loss(y_test[[c]].values.transpose()[0], bst.predict(dtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012120738780624358"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(xgb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv('test.csv')\n",
    "test_nblr = pd.read_csv('nblr_submission.csv', usecols=classes).rename(columns={c:'nblr_'+c for c in classes})\n",
    "test_cnn = pd.read_csv('conv_submission_keras_trainable_embedding_1epoch.csv', usecols=classes).rename(columns={c:'cnn_'+c for c in classes})\n",
    "test_rnn = pd.read_csv('rnn_submission_keras_gru.csv', usecols=classes).rename(columns={c:'rnn_'+c for c in classes})\n",
    "test = pd.concat([test_raw, test_nblr, test_cnn, test_rnn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = np.zeros((len(test_raw), len(classes)))\n",
    "for i, c in enumerate(classes):\n",
    "    bst = trees[c]\n",
    "    dtest = xgb.DMatrix(test.drop(columns=['id', 'comment_text']))\n",
    "    X_pred[:,i] = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([test_raw[['id']], pd.DataFrame(X_pred, columns = classes)], axis=1)\n",
    "df_combined.to_csv('combined_0.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
